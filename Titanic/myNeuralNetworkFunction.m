function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 21-Jul-2018 10:21:26.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 6xQ matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 1xQ matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [1;0;0;0;0;0];
x1_step1.gain = [1;2;2;0.25;0.333333333333333;0.333333333333333];
x1_step1.ymin = -1;

% Layer 1
b1 = [-2.1471972139322042;1.5966519000706338;1.116276889920258;-0.580444650052931;0.22481556038810835;-0.23959272785977284;-0.6407354632756056;-1.0681140685811845;-1.6059017980363663;-2.064914030543461];
IW1_1 = [0.10043216225207713 -0.34744091860885606 -1.3404768178016877 -1.2537217667153002 0.14670493402520562 -0.39252961643186524;-1.1569698546570468 -0.31348357730264692 0.75738638092594768 0.67120760362530163 -0.65729285449506103 -1.141456533631189;-0.79306964185602957 -0.67030354460475516 0.63322120427774098 0.55332916262823884 1.2371249104055135 1.0366335197541625;0.68520440075619105 -0.7101987685601121 1.4096488798938482 1.0513876785530176 0.020128212168655443 -0.49502658268088962;-0.1646953292574948 0.60263010930676808 -1.3550228680427314 -0.46903122758656879 -1.073075461034432 0.79225902123978897;-0.6992339216428235 -1.0750022071379353 0.57740359913421546 0.055134369660835236 1.034246415459807 1.0940538722881297;-0.88010946367803022 0.87983081033448074 0.63829141475210693 -0.17676217268324013 -1.3813711857249946 0.47693847624974622;-0.88194613331269678 -0.65888985614811946 0.9636174017541681 -1.0157844917596475 -1.1009603246213466 0.07877209954106891;-0.022487250635196201 -0.51140590514260353 0.15303461332305118 1.1559813044555909 -0.92333423391014224 1.3001497738563961;-1.1012554434224866 0.3910854159815963 0.68797383873891294 -1.0039299868711598 0.67951925132368829 -0.85570927640918348];

% Layer 2
b2 = 0.19832392538868571;
LW2_1 = [-0.91915460353059908 -1.0319770153121979 -0.61072349838695239 -0.91905937326395304 1.345207163103324 -0.4075013895693943 0.37577554202001306 0.52286395284202558 0.49331655492819143 0.81778848826762263];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX, X = {X}; end;

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},2); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX, Y = cell2mat(Y); end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Positive Transfer Function
function a = logsig_apply(n,~)
a = 1 ./ (1 + exp(-n));
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
